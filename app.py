import os
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
import shap

# ====================================================================
# ğŸš¨ ë°˜ë“œì‹œ ìµœìƒë‹¨ì— ìœ„ì¹˜í•´ì•¼ í•¨!
# ====================================================================
st.set_page_config(
    page_title="AI ë¹„ë°€ìƒë‹´ì‚¬", 
    layout="wide", 
    page_icon="ğŸ¤–",
    initial_sidebar_state="expanded"
)

# ====================================================================
# ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼
# ====================================================================
st.markdown("""
<style>
    /* ë©”ì¸ í—¤ë” ìŠ¤íƒ€ì¼ */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        border-left: 4px solid #667eea;
    }
    
    /* ìœ„í—˜ë„ í‘œì‹œ */
    .risk-high {
        color: #ef4444;
        font-weight: bold;
        font-size: 1.2rem;
    }
    .risk-medium {
        color: #f59e0b;
        font-weight: bold;
        font-size: 1.2rem;
    }
    .risk-low {
        color: #10b981;
        font-weight: bold;
        font-size: 1.2rem;
    }
    
    /* ì„¹ì…˜ í—¤ë” */
    .section-header {
        background: #f8fafc;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stButton > button {
        width: 100%;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: 500;
    }
    
    /* ì •ë³´ ë°•ìŠ¤ */
    .info-box {
        background: #f0f9ff;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #3b82f6;
        margin: 1rem 0;
    }
    
    /* ê²½ê³  ë°•ìŠ¤ */
    .warning-box {
        background: #fef3c7;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #f59e0b;
        margin: 1rem 0;
    }
    
    /* ì„±ê³µ ë°•ìŠ¤ */
    .success-box {
        background: #d1fae5;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #10b981;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ====================================================================
# A. ì´ˆê¸° ì„¤ì • ë° ë¦¬ì†ŒìŠ¤ ë¡œë“œ
# ====================================================================

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit Cloudì—ì„œëŠ” secrets ì‚¬ìš©, ë¡œì»¬ì—ì„œëŠ” .env ì‚¬ìš©
if 'GEMINI_API_KEY' in st.secrets:
    API_KEY = st.secrets["GEMINI_API_KEY"]
else:
    API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    st.error("âš ï¸ GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
    st.info("ë¡œì»¬: .env íŒŒì¼ì— ì„¤ì • | Streamlit Cloud: secrets.tomlì— ì„¤ì •")
    st.stop()

os.environ["GEMINI_API_KEY"] = API_KEY

# ===== ğŸ“‚ ê²½ë¡œ ì„¤ì • (ë°°í¬ìš© ìƒëŒ€ ê²½ë¡œ) =====
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€
BASE_PATH = os.path.dirname(os.path.abspath(__file__))
DATA_FOLDER = os.path.join(BASE_PATH, 'data')
PDF_FOLDER = os.path.join(DATA_FOLDER, 'pdf')

MODEL_PATH = os.path.join(DATA_FOLDER, 'lgbm_closure_predictor.pkl')
DATA_PATH = os.path.join(DATA_FOLDER, 'integrated_final_dataset.csv')

# ì»¬ëŸ¼ëª… í•œê¸€ ë§¤í•‘ ì‚¬ì „
COLUMN_KOREAN_NAMES = {
    'OPERATING_DAYS': 'ìš´ì˜ ê¸°ê°„',
    'MCT_OPE_MS_CN_RANK': 'ìš´ì˜ê°œì›”ìˆ˜ ë“±ê¸‰',
    'RC_M1_SAA_RANK': 'ë§¤ì¶œê¸ˆì•¡ ë“±ê¸‰',
    'RC_M1_TO_UE_CT_RANK': 'ë§¤ì¶œê±´ìˆ˜ ë“±ê¸‰',
    'RC_M1_UE_CUS_CN_RANK': 'ê³ ê° ìˆ˜ ë“±ê¸‰',
    'RC_M1_AV_NP_AT_RANK': 'ê°ë‹¨ê°€ ë“±ê¸‰',
    'APV_CE_RAT_RANK': 'ì·¨ì†Œìœ¨ ë“±ê¸‰',
    'DLV_SAA_RAT': 'ë°°ë‹¬ë§¤ì¶œ ë¹„ìœ¨',
    'M1_SME_RY_SAA_RAT': 'ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œê¸ˆì•¡',
    'M1_SME_RY_CNT_RAT': 'ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë§¤ì¶œê±´ìˆ˜',
    'M12_SME_RY_SAA_PCE_RT': 'ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„',
    'M12_SME_BZN_SAA_PCE_RT': 'ìƒê¶Œ ë‚´ ë§¤ì¶œ ìˆœìœ„',
    'M12_SME_RY_ME_MCT_RAT': 'ì—…ì¢… ë‚´ íì—… ê°€ë§¹ì  ë¹„ì¤‘',
    'M12_SME_BZN_ME_MCT_RAT': 'ìƒê¶Œ ë‚´ íì—… ê°€ë§¹ì  ë¹„ì¤‘',
    'M12_MAL_1020_RAT': 'ë‚¨ì„± 20ëŒ€ì´í•˜ ê³ ê° ë¹„ì¤‘',
    'M12_MAL_30_RAT': 'ë‚¨ì„± 30ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_MAL_40_RAT': 'ë‚¨ì„± 40ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_MAL_50_RAT': 'ë‚¨ì„± 50ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_MAL_60_RAT': 'ë‚¨ì„± 60ëŒ€ì´ìƒ ê³ ê° ë¹„ì¤‘',
    'M12_FME_1020_RAT': 'ì—¬ì„± 20ëŒ€ì´í•˜ ê³ ê° ë¹„ì¤‘',
    'M12_FME_30_RAT': 'ì—¬ì„± 30ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_FME_40_RAT': 'ì—¬ì„± 40ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_FME_50_RAT': 'ì—¬ì„± 50ëŒ€ ê³ ê° ë¹„ì¤‘',
    'M12_FME_60_RAT': 'ì—¬ì„± 60ëŒ€ì´ìƒ ê³ ê° ë¹„ì¤‘',
    'MCT_UE_CLN_REU_RAT': 'ì¬ë°©ë¬¸ ê³ ê° ë¹„ì¤‘',
    'MCT_UE_CLN_NEW_RAT': 'ì‹ ê·œ ê³ ê° ë¹„ì¤‘',
    'RC_M1_SHC_RSD_UE_CLN_RAT': 'ê±°ì£¼ ì´ìš© ê³ ê° ë¹„ìœ¨',
    'RC_M1_SHC_WP_UE_CLN_RAT': 'ì§ì¥ ì´ìš© ê³ ê° ë¹„ìœ¨',
    'RC_M1_SHC_FLP_UE_CLN_RAT': 'ìœ ë™ì¸êµ¬ ì´ìš© ê³ ê° ë¹„ìœ¨',
    'HPSN_MCT_ZCD_NM': 'ì—…ì¢…',
    'MCT_SIGUNGU_NM': 'ê°€ë§¹ì  ì§€ì—­'
}

# PDF íŒŒì¼ ëª©ë¡
PDF_FILES = [
    '(ì°¸ê³ 1)  ê²½ì˜ì•ˆì •ì§€ì›ì‚¬ì—… ë¹„êµí‘œ(í¬ë ˆë”§ vs ë¹„ì¦ˆí”ŒëŸ¬ìŠ¤ vs ë°°ë‹¬â€§íƒë°°).pdf',
    '[eBook]2024ë…„ ì†Œìƒê³µì¸ ì—­ëŸ‰ê°•í™”ì‚¬ì—… ìš°ìˆ˜ì‚¬ë¡€ì§‘.pdf',
    'â˜…â˜…2024 ê¸°ì—…ê°€í˜• ì†Œìƒê³µì¸ ìš°ìˆ˜ì‚¬ë¡€ì§‘_ì €ìš©ëŸ‰.pdf',
    '2025ë…„ ì¤‘ì†Œê¸°ì—…ìœ¡ì„±ìê¸ˆ ìœµìì§€ì› ë³€ê²½ê³„íš ê³µê³ ë¬¸(251020).pdf',
    '250527_ì†Œìƒê³µì¸_ë¶€ë‹´ê²½ê°_í¬ë ˆë”§_ì§€ì›ì‚¬ì—…_ì„¤ëª…ìë£Œ(ì§€ì—­í™ë³´ìš©,_2ìª½).pdf',
    'ì€í–‰ê¶Œ ì†Œìƒê³µì¸ ì§€ì›ë°©ì•ˆ(ê¸ˆìœµìœ„ìë£Œ).pdf',
    'ì†Œìƒê³µì¸ ë¶€ë‹´ê²½ê° í¬ë ˆë”§ ì§€ì›ì‚¬ì—….pdf'  # â† ìƒˆë¡œ ì¶”ê°€!
]
PDF_PATHS = [os.path.join(PDF_FOLDER, f) for f in PDF_FILES]

# LLM ì´ˆê¸°í™”
@st.cache_resource
def get_llm():
    """LLM ì´ˆê¸°í™” (ìºì‹±)"""
    try:
        return ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            api_key=API_KEY,
            temperature=0.2
        )
    except Exception as e:
        st.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

llm = get_llm()

# --- ë¦¬ì†ŒìŠ¤ ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_resource(show_spinner=False)
def load_resources():
    """ëª¨ë¸, ë°ì´í„°, Vector DBë¥¼ í•œ ë²ˆë§Œ ë¡œë“œ"""
    
    loading_placeholder = st.empty()
    
    try:
        # 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
        loading_placeholder.info("ğŸ”„ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...")
        
        if not os.path.exists(MODEL_PATH):
            st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
            return None, None, None, None, None
        if not os.path.exists(DATA_PATH):
            st.error(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}")
            return None, None, None, None, None
        
        lgbm_model = joblib.load(MODEL_PATH)
        df = pd.read_csv(DATA_PATH, encoding='utf-8')
        
        # 2. SHAP Explainer ìƒì„±
        df_latest = df.loc[df.groupby('ENCODED_MCT')['TA_YM'].idxmax()].copy()
        
        # êµ¬ê°„ ë°ì´í„° â†’ ìˆ«ìë¡œ ë³€í™˜
        rank_cols = ['MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 
                    'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT', 'APV_CE_RAT']
        
        for col in rank_cols:
            if col in df_latest.columns:
                df_latest[f'{col}_RANK'] = df_latest[col].astype(str).str.split('_').str[0].apply(
                    lambda x: int(x) if x.isdigit() else np.nan
                )
                df_latest = df_latest.drop(columns=[col])
        
        # í”¼ì²˜ ì»¬ëŸ¼ ì¶”ì¶œ
        exclude_cols = ['ENCODED_MCT', 'TA_YM', 'MCT_ME_D', 'ARE_D', 'TA_YM_DT',
                       'HPSN_MCT_BZN_CD_NM', 'MCT_BSE_AR', 'MCT_NM', 'MCT_BRD_NUM']
        features = [col for col in df_latest.columns if col not in exclude_cols and col != 'IS_CLOSED']
        
        # SHAPìš© ìƒ˜í”Œ ë°ì´í„°
        X_sample = df_latest[features].copy()
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ category íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        categorical_features = ['HPSN_MCT_ZCD_NM', 'MCT_SIGUNGU_NM']
        for col in categorical_features:
            if col in X_sample.columns:
                X_sample[col] = X_sample[col].astype('category')
        
        # ìˆ«ìí˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        numerical_cols = X_sample.select_dtypes(include=[np.number]).columns
        X_sample[numerical_cols] = X_sample[numerical_cols].fillna(0)
        
        X_sample = X_sample.head(100)
        explainer = shap.TreeExplainer(lgbm_model)
        
        # 3. RAG Vector DB êµ¬ì¶•
        documents = []
        loaded_pdfs = []
        
        for pdf_path in PDF_PATHS:
            if os.path.exists(pdf_path):
                try:
                    loader = PyPDFLoader(pdf_path)
                    docs = loader.load()
                    documents.extend(docs)
                    loaded_pdfs.append(os.path.basename(pdf_path))
                except Exception as e:
                    pass
        
        if not documents:
            st.error("âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
            return None, None, None, None, None
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)
        
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            google_api_key=API_KEY
        )
        vectorstore = FAISS.from_documents(texts, embeddings)
        
        loading_placeholder.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ (ë°ì´í„°: {len(df):,}ê±´, PDF: {len(loaded_pdfs)}ê°œ)")
        
        return lgbm_model, df, explainer, vectorstore, features
    
    except Exception as e:
        loading_placeholder.error(f"âŒ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None, None, None, None, None

# ë¦¬ì†ŒìŠ¤ ë¡œë“œ
lgbm_model, df_final, explainer, vectorstore, feature_names = load_resources()


# ====================================================================
# B. í•µì‹¬ í•¨ìˆ˜: ì˜ˆì¸¡ ë° RAG ì „ëµ ìƒì„±
# ====================================================================

def interpret_rank(rank_value):
    """ë“±ê¸‰ ë°ì´í„°ë¥¼ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í•´ì„ (6ë‹¨ê³„)"""
    try:
        rank_str = str(rank_value)
        
        # "1_10%ì´í•˜" ë˜ëŠ” "6_ìƒìœ„6êµ¬ê°„(í•˜ìœ„1êµ¬ê°„)" í˜•íƒœ íŒŒì‹±
        if '_' in rank_str:
            rank_num = rank_str.split('_')[0]
            rank_num = int(rank_num)
            
            # 6ë‹¨ê³„ í‰ê°€
            if rank_num == 1:
                return "â­â­ ë§¤ìš° ì¢‹ìŒ (ìƒìœ„ 10%)", "success"
            elif rank_num == 2:
                return "â­ ì¢‹ìŒ (ìƒìœ„ 10-30%)", "success"
            elif rank_num == 3:
                return "ğŸŸ¢ ë‹¤ì†Œ ì¢‹ìŒ (ìƒìœ„ 30-50%)", "info"
            elif rank_num == 4:
                return "ğŸŸ¡ ë‹¤ì†Œ ë‚˜ì¨ (í•˜ìœ„ 25-50%)", "warning"
            elif rank_num == 5:
                return "ğŸŸ  ë‚˜ì¨ (í•˜ìœ„ 10-25%)", "warning"
            elif rank_num == 6:
                return "ğŸ”´ ë§¤ìš° ë‚˜ì¨ (í•˜ìœ„ 10%)", "danger"
        
        return rank_value, "info"
    except:
        return rank_value, "info"


def interpret_percentile(value):
    """ë°±ë¶„ìœ„ë¥¼ í•´ì„í•˜ì—¬ ìˆœìœ„ë¡œ í‘œí˜„"""
    try:
        pct = float(value)
        if pct <= 10:
            return f"â­ ìµœìƒìœ„ {pct:.1f}% (ìƒìœ„ê¶Œ)", "success"
        elif pct <= 25:
            return f"ğŸŸ¢ ìƒìœ„ {pct:.1f}%", "success"
        elif pct <= 50:
            return f"ğŸŸ¡ ì¤‘ìƒìœ„ {pct:.1f}%", "warning"
        elif pct <= 75:
            return f"ğŸŸ  ì¤‘í•˜ìœ„ {pct:.1f}%", "warning"
        else:
            return f"ğŸ”´ í•˜ìœ„ {pct:.1f}%", "danger"
    except:
        return value, "info"


def interpret_ratio(value, label):
    """ë¹„ìœ¨ ë°ì´í„° í•´ì„"""
    try:
        ratio = float(value)
        
        if 'ì—…ì¢…í‰ê· ëŒ€ë¹„' in label:
            if ratio >= 100:
                return f"â­ ìš°ìˆ˜ (ì—…ì¢…í‰ê· ì˜ {ratio:.0f}%)", "success"
            elif ratio >= 80:
                return f"ğŸŸ¢ ì–‘í˜¸ (ì—…ì¢…í‰ê· ì˜ {ratio:.0f}%)", "success"
            elif ratio >= 60:
                return f"ğŸŸ¡ ë³´í†µ (ì—…ì¢…í‰ê· ì˜ {ratio:.0f}%)", "warning"
            else:
                return f"ğŸ”´ ë¶€ì§„ (ì—…ì¢…í‰ê· ì˜ {ratio:.0f}%)", "danger"
        
        elif 'ì¬ë°©ë¬¸' in label:
            if ratio >= 50:
                return f"â­ ìš°ìˆ˜ ({ratio:.1f}%)", "success"
            elif ratio >= 35:
                return f"ğŸŸ¢ ì–‘í˜¸ ({ratio:.1f}%)", "success"
            elif ratio >= 25:
                return f"ğŸŸ¡ ë³´í†µ ({ratio:.1f}%)", "warning"
            else:
                return f"ğŸ”´ ë‚®ìŒ ({ratio:.1f}%)", "danger"
        
        elif 'ë°°ë‹¬ë§¤ì¶œ' in label:
            if ratio >= 40:
                return f"ğŸ“± ë†’ìŒ ({ratio:.1f}%)", "info"
            elif ratio >= 20:
                return f"ğŸ“± ë³´í†µ ({ratio:.1f}%)", "info"
            else:
                return f"ğŸ“± ë‚®ìŒ ({ratio:.1f}%)", "info"
        
        elif 'ì·¨ì†Œ' in label:
            if ratio <= 3:
                return f"â­ ìš°ìˆ˜ ({ratio:.1f}%)", "success"
            elif ratio <= 7:
                return f"ğŸŸ¢ ì–‘í˜¸ ({ratio:.1f}%)", "success"
            elif ratio <= 12:
                return f"ğŸŸ¡ ì£¼ì˜ ({ratio:.1f}%)", "warning"
            else:
                return f"ğŸ”´ ë†’ìŒ ({ratio:.1f}%)", "danger"
        
        return f"{ratio:.1f}%", "info"
    except:
        return value, "info"


def extract_merchant_data(mct_id, df, features):
    """ê°€ë§¹ì ì˜ ì‹¤ì œ ë°ì´í„° ê°’ ì¶”ì¶œ ë° í•´ì„ (ê·¼ê±° ìë£Œìš©)"""
    try:
        mct_data = df[df['ENCODED_MCT'] == mct_id]
        if mct_data.empty:
            return None
        
        latest_data = mct_data.loc[mct_data['TA_YM'].idxmax()].copy()
        
        # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ ë° í•´ì„
        data_dict = {}
        
        # ë“±ê¸‰ ì§€í‘œë“¤ (í•´ì„ í•„ìš”)
        if 'RC_M1_SAA' in latest_data.index:
            interpreted, status = interpret_rank(latest_data['RC_M1_SAA'])
            data_dict['ğŸ’° ë§¤ì¶œê¸ˆì•¡'] = (interpreted, status)
        
        if 'RC_M1_TO_UE_CT' in latest_data.index:
            interpreted, status = interpret_rank(latest_data['RC_M1_TO_UE_CT'])
            data_dict['ğŸ§¾ ë§¤ì¶œê±´ìˆ˜'] = (interpreted, status)
        
        if 'RC_M1_UE_CUS_CN' in latest_data.index:
            interpreted, status = interpret_rank(latest_data['RC_M1_UE_CUS_CN'])
            data_dict['ğŸ‘¥ ê³ ê°ìˆ˜'] = (interpreted, status)
        
        if 'RC_M1_AV_NP_AT' in latest_data.index:
            interpreted, status = interpret_rank(latest_data['RC_M1_AV_NP_AT'])
            data_dict['ğŸ’µ ê°ë‹¨ê°€'] = (interpreted, status)
        
        if 'APV_CE_RAT' in latest_data.index:
            interpreted, status = interpret_rank(latest_data['APV_CE_RAT'])
            data_dict['âŒ ì·¨ì†Œìœ¨'] = (interpreted, status)
        
        # ë¹„ìœ¨ ì§€í‘œ
        if 'MCT_UE_CLN_REU_RAT' in latest_data.index:
            interpreted, status = interpret_ratio(latest_data['MCT_UE_CLN_REU_RAT'], 'ì¬ë°©ë¬¸')
            data_dict['ğŸ”„ ì¬ë°©ë¬¸ìœ¨'] = (interpreted, status)
        
        if 'DLV_SAA_RAT' in latest_data.index:
            interpreted, status = interpret_ratio(latest_data['DLV_SAA_RAT'], 'ë°°ë‹¬ë§¤ì¶œ')
            data_dict['ğŸ›µ ë°°ë‹¬ë§¤ì¶œë¹„ìœ¨'] = (interpreted, status)
        
        # ì—…ì¢…/ìƒê¶Œ ë¹„êµ
        if 'M1_SME_RY_SAA_RAT' in latest_data.index:
            interpreted, status = interpret_ratio(latest_data['M1_SME_RY_SAA_RAT'], 'ì—…ì¢…í‰ê· ëŒ€ë¹„')
            data_dict['ğŸ“Š ì—…ì¢… ëŒ€ë¹„ ë§¤ì¶œ'] = (interpreted, status)
        
        if 'M12_SME_RY_SAA_PCE_RT' in latest_data.index:
            interpreted, status = interpret_percentile(latest_data['M12_SME_RY_SAA_PCE_RT'])
            data_dict['ğŸ† ì—…ì¢… ë‚´ ìˆœìœ„'] = (interpreted, status)
        
        if 'M12_SME_BZN_SAA_PCE_RT' in latest_data.index:
            interpreted, status = interpret_percentile(latest_data['M12_SME_BZN_SAA_PCE_RT'])
            data_dict['ğŸ“ ìƒê¶Œ ë‚´ ìˆœìœ„'] = (interpreted, status)
        
        # ìš´ì˜ ê¸°ê°„
        if 'OPERATING_DAYS' in latest_data.index:
            days = int(latest_data['OPERATING_DAYS'])
            months = days // 30
            years = months // 12
            remaining_months = months % 12
            
            if years > 0:
                period_str = f"â±ï¸ {years}ë…„ {remaining_months}ê°œì›” ìš´ì˜"
            else:
                period_str = f"â±ï¸ {months}ê°œì›” ìš´ì˜"
            
            data_dict['ğŸ—“ï¸ ìš´ì˜ê¸°ê°„'] = (period_str, "info")
        
        return data_dict
    
    except Exception as e:
        return None


def predict_risk_with_shap(mct_id, df, model, explainer, features):
    """ì‹¤ì œ LightGBM ëª¨ë¸ë¡œ íì—… ìœ„í—˜ ì˜ˆì¸¡ + SHAP ë¶„ì„"""
    try:
        # 1. í•´ë‹¹ ê°€ë§¹ì ì˜ ìµœì‹  ë°ì´í„° ì¶”ì¶œ
        mct_data = df[df['ENCODED_MCT'] == mct_id]
        if mct_data.empty:
            return None, None, None, None, None
        
        latest_data = mct_data.loc[mct_data['TA_YM'].idxmax()].copy()
        
        # 2. êµ¬ê°„ ë°ì´í„° â†’ ìˆ«ìë¡œ ë³€í™˜
        rank_cols = ['MCT_OPE_MS_CN', 'RC_M1_SAA', 'RC_M1_TO_UE_CT', 
                    'RC_M1_UE_CUS_CN', 'RC_M1_AV_NP_AT', 'APV_CE_RAT']
        
        for col in rank_cols:
            if col in latest_data.index:
                val = str(latest_data[col]).split('_')[0]
                try:
                    latest_data[f'{col}_RANK'] = int(val)
                except:
                    latest_data[f'{col}_RANK'] = 0
                latest_data = latest_data.drop(col)
        
        # 3. ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ category íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        categorical_features = ['HPSN_MCT_ZCD_NM', 'MCT_SIGUNGU_NM']
        
        # 4. í”¼ì²˜ ì¤€ë¹„
        X_dict = {}
        for feat in features:
            if feat in latest_data.index:
                val = latest_data[feat]
                X_dict[feat] = val if pd.notna(val) else 0
            else:
                X_dict[feat] = 0
        
        X = pd.DataFrame([X_dict])
        
        # 5. ë²”ì£¼í˜• ì»¬ëŸ¼ì„ category íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        for col in categorical_features:
            if col in X.columns:
                X[col] = X[col].astype('category')
        
        # 6. ìˆ«ìí˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        numerical_cols = X.select_dtypes(include=[np.number]).columns
        X[numerical_cols] = X[numerical_cols].fillna(0)
        
        # 7. ì˜ˆì¸¡ (í™•ë¥  â†’ ì ìˆ˜ë¡œ ë³€í™˜)
        risk_prob = model.predict_proba(X)[0][1]
        risk_score = risk_prob * 100
        
        # 8. SHAP ê°’ ê³„ì‚°
        shap_values = explainer.shap_values(X)
        if isinstance(shap_values, list):
            shap_values = shap_values[1][0]
        else:
            shap_values = shap_values[0]
        
        # 9. ìœ„í—˜/ì•ˆì „ ìš”ì¸ ì¶”ì¶œ (í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜)
        shap_df = pd.DataFrame({
            'feature': features,
            'shap_value': shap_values
        }).sort_values('shap_value', ascending=False)
        
        risk_factors_raw = shap_df[shap_df['shap_value'] > 0].head(3)['feature'].tolist()
        safe_factors_raw = shap_df[shap_df['shap_value'] < 0].tail(3)['feature'].tolist()
        
        # í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜
        risk_factors = [COLUMN_KOREAN_NAMES.get(f, f) for f in risk_factors_raw]
        safe_factors = [COLUMN_KOREAN_NAMES.get(f, f) for f in safe_factors_raw]
        
        # 10. ë©”íƒ€ ì •ë³´ ì¶”ì¶œ
        ì—…ì¢… = latest_data.get('HPSN_MCT_ZCD_NM', 'ì•Œ ìˆ˜ ì—†ìŒ')
        ì§€ì—­ = latest_data.get('MCT_SIGUNGU_NM', 'ì„±ë™êµ¬')
        
        return risk_score, risk_factors, safe_factors, ì—…ì¢…, ì§€ì—­
    
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None, None, None, None, None


def generate_diagnosis_comment(risk_score, risk_factors, safe_factors, ì—…ì¢…, ì§€ì—­, llm, vectorstore, merchant_data):
    """ì§„ë‹¨ ê²°ê³¼ì— ëŒ€í•œ AI ì½”ë©˜íŠ¸ ìƒì„± (RAG í™œìš©) - ë°ì´í„° ê·¼ê±° í¬í•¨"""
    if not llm:
        return "âš ï¸ AI ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
    
    try:
        # ìœ„í—˜ë„ì— ë”°ë¥¸ ìƒíƒœ íŒë‹¨
        if risk_score >= 70:
            status = "ê³ ìœ„í—˜"
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ íì—… ë°©ì§€ ì§€ì› ì •ì±… ìœµì"
        elif risk_score >= 40:
            status = "ì£¼ì˜ í•„ìš”"
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ ë§¤ì¶œ ì¦ëŒ€ ê²½ì˜ì•ˆì • ì§€ì›"
        else:
            status = "ì•ˆì •"
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ ì„±ì¥ ì§€ì› ì •ì±… ì‚¬ë¡€"
        
        # RAGë¡œ ê´€ë ¨ ì •ì±… ê²€ìƒ‰
        relevant_docs = vectorstore.similarity_search(query, k=2)
        policy_context = "\n".join([doc.page_content[:300] for doc in relevant_docs])
        
        # ì¶œì²˜ ë¬¸ì„œ ì¶”ì¶œ
        source_docs = []
        for doc in relevant_docs:
            if hasattr(doc, 'metadata') and 'source' in doc.metadata:
                source_path = doc.metadata['source']
                source_filename = os.path.basename(source_path)
                if source_filename not in source_docs:
                    source_docs.append(source_filename)
        
        # ì‹¤ì œ ë°ì´í„° ì •ë³´ ì¶”ê°€ (í•´ì„ëœ í˜•íƒœ)
        data_info = ""
        if merchant_data:
            data_info = "\n[ê°€ë§¹ì  ê²½ì˜ ì§€í‘œ (ì„±ë™êµ¬ ë¹„êµ)]\n"
            for key, value_tuple in merchant_data.items():
                interpreted_value, _ = value_tuple
                data_info += f"- {key}: {interpreted_value}\n"
        
        prompt = f"""
ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ ê²½ì˜ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§„ë‹¨ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ì—…ì£¼ê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸš¨ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­:
1. ì•„ë˜ [ê´€ë ¨ ì •ë¶€ ì§€ì› ì •ì±…]ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ì •ì±…ëª…, ì§€ì›ê¸ˆì•¡, ì‹ ì²­ê¸°ê°„ì€ ë¬¸ì„œì— ì •í™•íˆ ë‚˜ì˜¨ ë‚´ìš©ë§Œ ì–¸ê¸‰
3. ë¬¸ì„œì— ì—†ëŠ” ì •ì±…ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
4. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "ê´€ë ¨ ê¸°ê´€ í™•ì¸ í•„ìš”"ë¼ê³  ëª…ì‹œ
5. ì¶”ì¸¡ì´ë‚˜ ìƒìƒìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”

**âš ï¸ ì¤‘ìš”: ëª¨ë“  ì œì•ˆê³¼ ì§„ë‹¨ì—ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ê·¼ê±°ë¥¼ í¬í•¨í•˜ë˜, ì¼ë°˜ ì‚¬ì¥ë‹˜ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.**

[ê°€ë§¹ì  ì •ë³´]
- ì—…ì¢…: {ì—…ì¢…}
- ì§€ì—­: {ì§€ì—­}
- íì—… ìœ„í—˜ë„: {risk_score:.1f}ì  ({status})

[ì£¼ìš” ìœ„í—˜ ìš”ì¸]
{chr(10).join(['- ' + f for f in risk_factors]) if risk_factors else '- ì—†ìŒ'}

[ì£¼ìš” ê°•ì ]
{chr(10).join(['- ' + f for f in safe_factors]) if safe_factors else '- ì—†ìŒ'}

{data_info}

[ê´€ë ¨ ì •ë¶€ ì§€ì› ì •ì±…]
{policy_context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **ì¼ë°˜ ì‚¬ì¥ë‹˜ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ** ë‹µë³€í•˜ì„¸ìš”:

**ğŸª í˜„ì¬ ìƒíƒœ**
(ê²½ì˜ ìƒíƒœë¥¼ ìœ„ ì§€í‘œë“¤ì„ ì¸ìš©í•˜ì—¬ ì‰½ê²Œ ì„¤ëª…. ì˜ˆ: "ë§¤ì¶œê¸ˆì•¡ì´ í•˜ìœ„ê¶Œì´ì§€ë§Œ, ì¬ë°©ë¬¸ìœ¨ì€ ìš°ìˆ˜í•œ í¸ì…ë‹ˆë‹¤")

**âš ï¸ ì£¼ì˜í•  ì **
(ìœ„í—˜ ìš”ì¸ì„ ìœ„ ì§€í‘œë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…. ì˜ˆ: "ì—…ì¢… ëŒ€ë¹„ ë§¤ì¶œì´ ë¶€ì§„í•˜ê³ , ìƒê¶Œ ë‚´ì—ì„œë„ í•˜ìœ„ê¶Œì— ì†í•©ë‹ˆë‹¤")

**ğŸ’ª ê°•ì **
(ê°•ì ì„ ìœ„ ì§€í‘œë¡œ ì„¤ëª…. ì˜ˆ: "ì¬ë°©ë¬¸ìœ¨ì´ ìš°ìˆ˜í•˜ì—¬ ë‹¨ê³¨ ê³ ê° í™•ë³´ëŠ” ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤")

**ğŸ ì¶”ì²œ ì§€ì› ì •ì±…**
(í˜„ì¬ ìƒíƒœì— ë§ëŠ” ì •ë¶€ ì§€ì› í”„ë¡œê·¸ë¨ 1-2ê°œ ì¶”ì²œ)

**ğŸ’¡ í•œ ì¤„ ì¡°ì–¸**
(ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸)
"""
        
        response = llm.invoke(prompt)
        return response.content, source_docs
    
    except Exception as e:
        return f"âŒ ì½”ë©˜íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", []


def generate_chatbot_response(user_question, diagnosis_info, chat_history, vectorstore, llm):
    """ì±—ë´‡ ì‘ë‹µ ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ + RAG í™œìš©)"""
    if not llm or not vectorstore:
        return "âš ï¸ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        # ì§„ë‹¨ ì •ë³´
        risk_score = diagnosis_info['risk_score']
        risk_factors = diagnosis_info['risk_factors']
        safe_factors = diagnosis_info['safe_factors']
        ì—…ì¢… = diagnosis_info['ì—…ì¢…']
        ì§€ì—­ = diagnosis_info['ì§€ì—­']
        
        # RAG ê²€ìƒ‰
        relevant_docs = vectorstore.similarity_search(user_question, k=2)
        rag_context = "\n".join([doc.page_content[:400] for doc in relevant_docs])
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 4ê°œë§Œ)
        recent_history = chat_history[-4:] if len(chat_history) > 4 else chat_history
        history_text = "\n".join([
            f"{'ì‚¬ìš©ì' if msg['role'] == 'user' else 'AI'}: {msg['content']}"
            for msg in recent_history
        ])
        
        prompt = f"""
ë‹¹ì‹ ì€ ì„±ë™êµ¬ ì†Œìƒê³µì¸ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ì—…ì£¼ì™€ì˜ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©° ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì£¼ì„¸ìš”.

ğŸš¨ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­:
1. ì•„ë˜ [ê´€ë ¨ ì •ì±… ë° ì‚¬ë¡€]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì°¸ê³ í•˜ì„¸ìš”
2. ì§€ì› í”„ë¡œê·¸ë¨ëª…, ê¸ˆì•¡, ì¡°ê±´ì€ ë¬¸ì„œ ë‚´ìš© ê·¸ëŒ€ë¡œë§Œ ì‘ì„±
3. ë¬¸ì„œì— ì—†ëŠ” í”„ë¡œê·¸ë¨ì´ë‚˜ ì‚¬ë¡€ëŠ” ì–¸ê¸‰ ê¸ˆì§€
4. ì„±ê³µ ì‚¬ë¡€ë„ ë¬¸ì„œì— ë‚˜ì˜¨ ê²ƒë§Œ ì‚¬ìš©
5. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”"ë¼ê³  ëª…ì‹œ

[ê°€ë§¹ì  ì§„ë‹¨ ì •ë³´]
- ì—…ì¢…: {ì—…ì¢…}
- ì§€ì—­: {ì§€ì—­}
- íì—… ìœ„í—˜ ì ìˆ˜: {risk_score:.1f}ì 
- ì£¼ìš” ìœ„í—˜ ìš”ì¸: {', '.join(risk_factors) if risk_factors else 'ì—†ìŒ'}
- ì£¼ìš” ê°•ì : {', '.join(safe_factors) if safe_factors else 'ì—†ìŒ'}

[ì´ì „ ëŒ€í™”]
{history_text if history_text else '(ì²« ì§ˆë¬¸ì…ë‹ˆë‹¤)'}

[ê´€ë ¨ ì •ì±…/ì‚¬ë¡€ ì •ë³´]
{rag_context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_question}

ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”:
1. **ì¹œê·¼í•˜ê³  ê³µê°í•˜ëŠ” í†¤**: "~í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”", "ê±±ì •ë˜ì‹œì£ ?" ë“±
2. **êµ¬ì²´ì ì¸ ë‹µë³€**: ì¶”ìƒì ì¸ ì¡°ì–¸ë³´ë‹¤ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ë²• ì œì‹œ
3. **ì§„ë‹¨ ì •ë³´ í™œìš©**: ìœ„ ì§„ë‹¨ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë§ì¶¤í˜• ë‹µë³€
4. **ì •ì±… ì •ë³´ ì—°ê²°**: ê´€ë ¨ ì •ë¶€ ì§€ì›ì´ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
5. **3-5ë¬¸ì¥ ë‚´ì™¸**: ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, í•µì‹¬ë§Œ ì „ë‹¬
6. **ëŒ€í™” ë§¥ë½ ìœ ì§€**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°

ë‹µë³€:
"""
        
        response = llm.invoke(prompt)
        return response.content
    
    except Exception as e:
        return f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}"


def generate_rag_strategy(risk_score, risk_factors, safe_factors, ì—…ì¢…, ì§€ì—­, vectorstore, llm, merchant_data):
    """RAG ê¸°ë°˜ ë§ì¶¤í˜• ì „ëµ ìƒì„± - ë°ì´í„° ê·¼ê±° í¬í•¨"""
    if not llm:
        return "âš ï¸ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", []
    
    if not vectorstore:
        return "âš ï¸ Vector DBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", []
    
    try:
        # 1. RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        if risk_score >= 70:
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ ê³ ìœ„í—˜ íì—… ë°©ì§€ ìœµì ì§€ì› ì •ì±… ì‚¬ë¡€"
        elif risk_score >= 40:
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ ë§¤ì¶œ ì¦ëŒ€ ë§ˆì¼€íŒ… ìš°ìˆ˜ ì‚¬ë¡€"
        else:
            query = f"{ì—…ì¢…} ì†Œìƒê³µì¸ ê²½ì˜ ì•ˆì •í™” ì„±ê³µ ì‚¬ë¡€"
        
        # 2. Vector DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = vectorstore.similarity_search(query, k=3)
        
        if not relevant_docs:
            context = "ê´€ë ¨ ì •ì±… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            context = "\n\n".join([doc.page_content[:500] for doc in relevant_docs])
        
        # ì¶œì²˜ ë¬¸ì„œ ì¶”ì¶œ
        source_docs = []
        for doc in relevant_docs:
            if hasattr(doc, 'metadata') and 'source' in doc.metadata:
                source_path = doc.metadata['source']
                source_filename = os.path.basename(source_path)
                if source_filename not in source_docs:
                    source_docs.append(source_filename)
        
        # ì‹¤ì œ ë°ì´í„° ì •ë³´ ì¶”ê°€ (í•´ì„ëœ í˜•íƒœ)
        data_info = ""
        if merchant_data:
            data_info = "\n[ê°€ë§¹ì  ê²½ì˜ ì§€í‘œ (ì„±ë™êµ¬ ë¹„êµ)]\n"
            for key, value_tuple in merchant_data.items():
                interpreted_value, _ = value_tuple
                data_info += f"- {key}: {interpreted_value}\n"
        
        # 3. Geminiì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¹ì‹ ì€ ì„±ë™êµ¬ ì†Œìƒê³µì¸ ì „ë¬¸ ê²½ì˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

**âš ï¸ ì¤‘ìš”: ëª¨ë“  ì „ëµê³¼ ì œì•ˆì—ëŠ” ìœ„ ê²½ì˜ ì§€í‘œë¥¼ ê·¼ê±°ë¡œ í¬í•¨í•˜ë˜, ì¼ë°˜ ì‚¬ì¥ë‹˜ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.**

[ê°€ë§¹ì  ì •ë³´]
- ì—…ì¢…: {ì—…ì¢…}
- ì§€ì—­: {ì§€ì—­}
- íì—… ìœ„í—˜ ì ìˆ˜: {risk_score:.1f}ì  (100ì  ë§Œì )

[AI ì§„ë‹¨ ê²°ê³¼]
- ì£¼ìš” ìœ„í—˜ ìš”ì¸: {', '.join(risk_factors) if risk_factors else 'ì—†ìŒ'}
- ì£¼ìš” ê°•ì : {', '.join(safe_factors) if safe_factors else 'ì—†ìŒ'}

{data_info}

[ê´€ë ¨ ì •ì±… ë° ì‚¬ë¡€ (RAG ê²€ìƒ‰ ê²°ê³¼)]
{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **ì¼ë°˜ ì‚¬ì¥ë‹˜ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ** ë‹µë³€í•˜ì„¸ìš”:

**ğŸ“Š ì¢…í•© ì§„ë‹¨**
- ìœ„ ê²½ì˜ ì§€í‘œë“¤ì„ ì¢…í•©í•˜ì—¬ í˜„ì¬ ìƒíƒœë¥¼ ì‰½ê²Œ ì„¤ëª…
- ì˜ˆ: "ë§¤ì¶œì€ í•˜ìœ„ê¶Œì´ì§€ë§Œ ì¬ë°©ë¬¸ìœ¨ì´ ìš°ìˆ˜í•˜ì—¬, ê¸°ì¡´ ê³ ê°ì€ ì˜ ê´€ë¦¬ë˜ê³  ìˆìŠµë‹ˆë‹¤"

**ğŸ’¡ ë§ì¶¤í˜• ì „ëµ**

**1. ì¦‰ì‹œ ì‹¤í–‰ ë°©ì•ˆ ğŸ’ª**
- **ì œì•ˆ**: (êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•)
- **ì´ìœ **: (ìœ„ ì§€í‘œ ì¤‘ ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ê²ƒì¸ì§€ ì„¤ëª…)
- **ì˜ˆìƒ íš¨ê³¼**: (ê°œì„  ëª©í‘œë¥¼ ì‰½ê²Œ ì„¤ëª…)

**2. ì •ë¶€ ì§€ì› í™œìš© ë°©ë²• ğŸ**
- **ì§€ì› í”„ë¡œê·¸ë¨**: (êµ¬ì²´ì ì¸ í”„ë¡œê·¸ë¨ëª…)
- **ì‹ ì²­ ìê²©**: (ìœ„ ì§€í‘œë¥¼ ë³´ì•˜ì„ ë•Œ í•´ë‹¹ë˜ëŠ”ì§€)
- **ì§€ì› ë‚´ìš©**: (ê¸ˆì•¡, ê¸°ê°„ ë“±)

**3. ë§ˆì¼€íŒ… ê°œì„  ì œì•ˆ ğŸ“±**
- **ì „ëµ**: (êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ë°©ë²•)
- **ê·¼ê±°**: (ìœ„ ì§€í‘œ ì¤‘ ì–´ë–¤ ë¶€ë¶„ì—ì„œ ì´ ì „ëµì´ í•„ìš”í•œì§€)
- **ì‹¤í–‰ ë°©ë²•**: (ë‹¨ê³„ë³„ ì‹¤í–‰ ë°©ë²•)

**ğŸ“Œ ì„±ê³µ ì‚¬ë¡€**
- ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ì„±ê³µí•œ ê°€ê²Œ ì‚¬ë¡€
- êµ¬ì²´ì ì¸ ì„±ê³¼ ìˆ˜ì¹˜ í¬í•¨

**âš ï¸ ìœ„ ê²½ì˜ ì§€í‘œë“¤ì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ë©°, ì‚¬ì¥ë‹˜ì´ "ì•„, ìš°ë¦¬ ê°€ê²Œ ìƒí™©ì— ë”± ë§ëŠ” ì¡°ì–¸ì´ë„¤!"ë¼ê³  ëŠë‚„ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•˜ì„¸ìš”.**
"""
        
        # 4. Gemini í˜¸ì¶œ
        response = llm.invoke(prompt)
        
        if not response or not response.content:
            return "âš ï¸ AI ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", source_docs
        
        return response.content, source_docs
    
    except Exception as e:
        import traceback
        return f"âŒ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}\n\n```\n{traceback.format_exc()}\n```", []


# ====================================================================
# C. Streamlit UI
# ====================================================================

def main():
    # í—¤ë”
    st.markdown("""
    <div class="main-header" style="padding: 1rem 2rem;">
        <div style="display: flex; align-items: center; justify-content: space-between;">
            <div>
                <h1 style="margin: 0; font-size: 1.8rem; font-weight: 700; line-height: 1.2;">
                    ğŸ¤– ì„±ë™ SAM <span style="font-size: 0.7rem; opacity: 0.7; font-weight: 400;">| Seongdong AI-based Management</span>
                </h1>
                <p style="font-size: 0.9rem; opacity: 0.85; margin: 0.3rem 0 0 0;">
                    âœ¨ ì„±ê³µì„ ìœ„í•œ ë™ë°˜ì, ì„±ë™êµ¬ ì†Œìƒê³µì¸ AI ë¹„ë°€ìƒë‹´ì‚¬ 'ì„±ë™SAM'ê³¼ í•¨ê»˜í•´ìš”!
                </p>
            </div>
        </div>
        <div style="display: flex; gap: 1rem; align-items: center; margin-top: 0.8rem; padding-top: 0.8rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <span style="font-size: 0.8rem; opacity: 0.8;">ğŸ“ˆ íì—… ìœ„í—˜ ì§„ë‹¨ (LightGBM+SHAP)</span>
            <span style="opacity: 0.5;">|</span>
            <span style="font-size: 0.8rem; opacity: 0.8;">ğŸ’¡ ë§ì¶¤í˜• ì „ëµ (RAG+Gemini 2.5)</span>
            <span style="opacity: 0.5;">|</span>
            <span style="font-size: 0.75rem; opacity: 0.6;">ğŸ“Š ì‹ í•œì¹´ë“œ ë°ì´í„° 86,590ê±´</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ’¡ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 1.5rem; 
                    border-radius: 10px; 
                    color: white;
                    margin-bottom: 1rem;">
            <h3 style="color: white; margin-top: 0;">ğŸš€ Quick Guide</h3>
            <div style="font-size: 1.1rem; line-height: 2rem;">
                <b>1ï¸âƒ£</b> ê°€ë§¹ì ID ì…ë ¥<br>
                <b>2ï¸âƒ£</b> 'ì§„ë‹¨ ì‹œì‘' í´ë¦­<br>
                <b>3ï¸âƒ£</b> AI ì½”ë©˜íŠ¸ í™•ì¸<br>
                <b>4ï¸âƒ£</b> ë§ì¶¤í˜• ì „ëµ ìƒì„±<br>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ë¦¬ì†ŒìŠ¤ ìƒíƒœ
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        if lgbm_model is not None and df_final is not None:
            st.success("âœ… ëª¨ë“  ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # metric ê¸€ì”¨ í¬ê¸° ì¡°ì ˆ
            st.markdown("""
            <style>
            [data-testid="stMetricValue"] {
                font-size: 1.3rem;
            }
            </style>
            """, unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ë°ì´í„°", f"{len(df_final):,}ê±´")
            with col2:
                st.metric("PDF", "6ê°œ")
        else:
            st.error("âŒ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì‹¤íŒ¨")
        
        st.markdown("---")
        
        # ì‹œìŠ¤í…œ ì •ë³´ (í•˜ë‹¨ìœ¼ë¡œ ì´ë™)
        with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´"):
            st.caption("**ë°ì´í„° í´ë”**")
            st.code("./data/", language=None)
            
            st.caption("**ëª¨ë¸ íŒŒì¼**")
            st.code(os.path.basename(MODEL_PATH), language=None)
            
            st.caption("**ë°ì´í„° íŒŒì¼**")
            st.code(os.path.basename(DATA_PATH), language=None)
            
            st.caption("**PDF íŒŒì¼**")
            st.code("./data/pdf/ (6ê°œ)", language=None)
    
    if lgbm_model is None or df_final is None:
        st.error("âŒ ë¦¬ì†ŒìŠ¤ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ê°€ë§¹ì  ID ì…ë ¥ ì˜ì—­
    st.markdown('<div class="section-header"><h3>ğŸ” ê°€ë§¹ì  ì§„ë‹¨</h3></div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 1])
    with col1:
        mct_id = st.text_input(
               "ğŸ” ê°€ë§¹ì  ID ì…ë ¥(Sample ID : AD57E72BC9, 869C372EFC, E8829764C8)", value="", key="mct_input", placeholder="ì˜ˆ: AD57E72BC9")
    st.caption("ğŸ’¡ ìš°ë¦¬ ê°€ê²Œì˜ ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸ë¥¼ ë„£ê³  Enter ì…ë ¥ í›„ 'ì§„ë‹¨ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
        
    with col2:
         diagnose_btn = st.button("ğŸ¥ ì§„ë‹¨ ì‹œì‘", type="primary", use_container_width=True)
    
    # ì§„ë‹¨ ì‹¤í–‰
    if diagnose_btn and mct_id:
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.diagnosis_done = False
        st.session_state.show_strategy = False
        st.session_state.chat_history = []
        # ì´ì „ ì „ëµ ì‚­ì œ
        if 'generated_strategy' in st.session_state:
            del st.session_state.generated_strategy
        if 'strategy_sources' in st.session_state:
            del st.session_state.strategy_sources
        
        with st.spinner("â³ AIê°€ ê²½ì˜ ìƒíƒœë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            risk_score, risk_factors, safe_factors, ì—…ì¢…, ì§€ì—­ = predict_risk_with_shap(
                mct_id, df_final, lgbm_model, explainer, feature_names
            )
            
            # ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            merchant_data = extract_merchant_data(mct_id, df_final, feature_names)
        
        if risk_score is None:
            st.error(f"âŒ '{mct_id}' ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sample_ids = df_final['ENCODED_MCT'].head(5).tolist()
            st.info(f"ğŸ’¡ ìƒ˜í”Œ ê°€ë§¹ì  ID: {', '.join(sample_ids)}")
            return
        
        # ì§„ë‹¨ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
        st.session_state.diagnosis_result = {
            'mct_id': mct_id,
            'risk_score': risk_score,
            'risk_factors': risk_factors,
            'safe_factors': safe_factors,
            'ì—…ì¢…': ì—…ì¢…,
            'ì§€ì—­': ì§€ì—­,
            'merchant_data': merchant_data
        }
        st.session_state.diagnosis_done = True
    
    # ì§„ë‹¨ ê²°ê³¼ í‘œì‹œ
    if st.session_state.get('diagnosis_done', False) and 'diagnosis_result' in st.session_state:
        result = st.session_state.diagnosis_result
        risk_score = result['risk_score']
        risk_factors = result['risk_factors']
        safe_factors = result['safe_factors']
        ì—…ì¢… = result['ì—…ì¢…']
        ì§€ì—­ = result['ì§€ì—­']
        mct_id = result['mct_id']
        merchant_data = result.get('merchant_data', None)
        
        # êµ¬ë¶„ì„ 
        st.markdown("---")
        
        # ê²°ê³¼ í‘œì‹œ - íƒ­ìœ¼ë¡œ êµ¬ì„±
        st.markdown('<div class="section-header"><h3>ğŸ“‹ ì§„ë‹¨ ê²°ê³¼</h3></div>', unsafe_allow_html=True)
        
        # ìœ„í—˜ë„ í‘œì‹œ
        col_a, col_b, col_c = st.columns([1, 1, 2])
        
        with col_a:
            if risk_score >= 70:
                status = "ğŸ”´ ê³ ìœ„í—˜"
                risk_class = "risk-high"
            elif risk_score >= 40:
                status = "ğŸŸ¡ ì£¼ì˜"
                risk_class = "risk-medium"
            else:
                status = "ğŸŸ¢ ì•ˆì •"
                risk_class = "risk-low"
            
            st.metric("íì—… ìœ„í—˜ ì ìˆ˜", f"{risk_score:.1f}ì ")
            st.markdown(f'<p class="{risk_class}">{status}</p>', unsafe_allow_html=True)
        
        with col_b:
            st.metric("ì—…ì¢…", ì—…ì¢…)
            st.metric("ì§€ì—­", ì§€ì—­)
        
        with col_c:
            st.markdown("**ğŸš¨ ì£¼ìš” ìœ„í—˜ ìš”ì¸**")
            if risk_factors:
                for factor in risk_factors:
                    st.markdown(f"â€¢ {factor}")
            else:
                st.markdown("â€¢ íŠ¹ì • ìœ„í—˜ ìš”ì¸ ì—†ìŒ")
            
            st.markdown("**âœ… ì£¼ìš” ê°•ì **")
            if safe_factors:
                for factor in safe_factors:
                    st.markdown(f"â€¢ {factor}")
            else:
                st.markdown("â€¢ íŠ¹ì • ê°•ì  ì—†ìŒ")
        
        # ì§„í–‰ ë°”
        st.markdown("**ìœ„í—˜ë„ ì‹œê°í™”**")
        
        # ìƒ‰ìƒ ê²°ì •
        if risk_score >= 70:
            bar_color = "#ef4444"  # ë¹¨ê°•
        elif risk_score >= 40:
            bar_color = "#f59e0b"  # ì£¼í™©
        else:
            bar_color = "#10b981"  # ì´ˆë¡
        
        # ì§„í–‰ ë°”ì™€ ë ˆì´ë¸”
        st.markdown(f"""
<div style="margin: 1rem 0;">
    <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
        <span style="color: #10b981; font-weight: 500;">â† ì•ˆì „</span>
        <span style="font-weight: 600; color: {bar_color}; font-size: 1.1rem;">
            í˜„ì¬: {risk_score:.1f}ì 
        </span>
        <span style="color: #ef4444; font-weight: 500;">ìœ„í—˜ â†’</span>
    </div>
    <div style="position: relative; margin-bottom: 3rem;">
        <div style="width: 100%; height: 30px; background: linear-gradient(to right, #10b981, #fbbf24, #ef4444); border-radius: 15px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);"></div>
        <div style="position: absolute; left: {risk_score}%; top: 15px; transform: translate(-50%, -50%); width: 24px; height: 24px; background: white; border: 4px solid {bar_color}; border-radius: 50%; box-shadow: 0 3px 8px rgba(0,0,0,0.3); z-index: 2;"></div>
        <div style="position: absolute; left: {risk_score}%; top: -25px; transform: translateX(-50%); background: {bar_color}; color: white; padding: 4px 12px; border-radius: 12px; font-weight: bold; font-size: 0.9rem; box-shadow: 0 2px 4px rgba(0,0,0,0.2); white-space: nowrap; z-index: 3;">{risk_score:.1f}ì </div>
        <div style="position: absolute; left: {risk_score}%; top: 35px; transform: translateX(-50%); width: 0; height: 0; border-left: 8px solid transparent; border-right: 8px solid transparent; border-top: 10px solid {bar_color}; z-index: 1;"></div>
    </div>
    <div style="display: flex; justify-content: space-between; font-size: 0.85rem; color: #666;">
        <span>0 (ë‚®ìŒ)</span>
        <span>50 (ë³´í†µ)</span>
        <span>100 (ë†’ìŒ)</span>
    </div>
</div>
""", unsafe_allow_html=True)


        
        # ğŸ“Š ì‹¤ì œ ë°ì´í„° ê·¼ê±° í‘œì‹œ
        if merchant_data:
            st.markdown("---")
            st.markdown('<div class="section-header"><h3>ğŸ“Š ìš°ë¦¬ ê°€ê²Œ ê²½ì˜ ì§€í‘œ (ì„±ë™êµ¬ ë¹„êµ)</h3></div>', unsafe_allow_html=True)
            st.caption("ğŸ’¡ ì„±ë™êµ¬ ì†Œìƒê³µì¸ë“¤ê³¼ ë¹„êµí•œ ìš°ë¦¬ ê°€ê²Œì˜ ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
            st.caption("ğŸ“Œ ì¶œì²˜: ì‹ í•œì¹´ë“œ ìš”ì‹ì—…ì¢… ë°ì´í„° 86,590ê±´ ë¶„ì„ìë£Œ")
            
            # ë°ì´í„°ë¥¼ 3ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ ì„œ í‘œì‹œ
            data_items = list(merchant_data.items())
            col_count = 3
            
            # 3ê°œì”© ë¬¶ì–´ì„œ í–‰ìœ¼ë¡œ í‘œì‹œ
            for i in range(0, len(data_items), col_count):
                cols = st.columns(col_count)
                
                for idx, (key, value_tuple) in enumerate(data_items[i:i+col_count]):
                    interpreted_value, status = value_tuple
                    
                    with cols[idx]:
                        # ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ ìŠ¤íƒ€ì¼
                        if status == "success":
                            bg_color = "#d1fae5"
                            border_color = "#10b981"
                        elif status == "warning":
                            bg_color = "#fef3c7"
                            border_color = "#f59e0b"
                        elif status == "danger":
                            bg_color = "#fee2e2"
                            border_color = "#ef4444"
                        else:
                            bg_color = "#f0f9ff"
                            border_color = "#3b82f6"
                        
                        st.markdown(f"""
                        <div style="background: {bg_color}; 
                                    padding: 1rem; 
                                    border-radius: 8px; 
                                    border-left: 4px solid {border_color};
                                    margin-bottom: 0.5rem;">
                            <div style="font-size: 0.9rem; color: #666; margin-bottom: 0.3rem;">{key}</div>
                            <div style="font-size: 1.1rem; font-weight: bold; color: #1a1a1a;">{interpreted_value}</div>
                        </div>
                        """, unsafe_allow_html=True)
        
        # AI ë¶„ì„ ì½”ë©˜íŠ¸
        st.markdown("---")
        st.markdown('<div class="section-header"><h3>ğŸ’¬ AI ì§„ë‹¨ ì½”ë©˜íŠ¸ (ê·¼ê±° ê¸°ë°˜)</h3></div>', unsafe_allow_html=True)
        
        with st.spinner("ğŸ¤– AIê°€ ì§„ë‹¨ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì •ì±…ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            analysis_comment, diagnosis_sources = generate_diagnosis_comment(
                risk_score, risk_factors, safe_factors, ì—…ì¢…, ì§€ì—­, llm, vectorstore, merchant_data
            )
        
        st.markdown(f'<div class="info-box">{analysis_comment}</div>', unsafe_allow_html=True)
        
        # ì°¸ê³  ìë£Œ ì¶œì²˜ í‘œì‹œ
        if diagnosis_sources:
            st.markdown("---")
            st.markdown('<div class="section-header"><h3>ğŸ“š ì°¸ê³  ìë£Œ (ì •ì±… ë¬¸ì„œ)</h3></div>', unsafe_allow_html=True)
            
            for idx, source in enumerate(diagnosis_sources, 1):
                # PDF íŒŒì¼ëª… ì •ë¦¬
                display_name = source.replace('.pdf', '').replace('_', ' ')
                
                # GitHub raw URL ìƒì„±
                github_url = f"https://raw.githubusercontent.com/ICeT-smk/seongdong-ai-consultant/main/data/pdf/{source}"
                
                # íŒŒì¼ ì•„ì´ì½˜ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.markdown(f"""
                <div style="background: #f8fafc; 
                            padding: 0.8rem; 
                            border-radius: 5px; 
                            border-left: 3px solid #667eea;
                            margin-bottom: 0.5rem;">
                    <div style="display: flex; align-items: center; justify-content: space-between;">
                        <div style="display: flex; align-items: center;">
                            <span style="font-size: 1.5rem; margin-right: 0.5rem;">ğŸ“„</span>
                            <span style="font-weight: 500;">{display_name}</span>
                        </div>
                        <a href="{github_url}" download="{source}" 
                           style="text-decoration: none; 
                                  background: #667eea; 
                                  color: white; 
                                  padding: 0.4rem 0.8rem; 
                                  border-radius: 5px; 
                                  font-size: 0.85rem;
                                  white-space: nowrap;">
                            ğŸ“¥ ë‹¤ìš´ë¡œë“œ
                        </a>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            
            st.caption("ğŸ’¡ ìœ„ ì •ë¶€ ì§€ì› ì •ì±… ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.")

        
 # ì±—ë´‡ ê¸°ëŠ¥
        st.markdown("---")
        st.markdown('<div class="section-header"><h3>ğŸ’¬ì„±ë™SAMê³¼ ììœ ìƒë‹´</h3></div>', unsafe_allow_html=True)
        st.caption("ì§„ë‹¨ ê²°ê³¼ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")
        
        # ì„¸ì…˜ ìƒíƒœì— ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        if 'current_diagnosis' not in st.session_state:
            st.session_state.current_diagnosis = None
        
        # í˜„ì¬ ì§„ë‹¨ ì •ë³´ ì €ì¥
        st.session_state.current_diagnosis = {
            'mct_id': mct_id,
            'risk_score': risk_score,
            'risk_factors': risk_factors,
            'safe_factors': safe_factors,
            'ì—…ì¢…': ì—…ì¢…,
            'ì§€ì—­': ì§€ì—­
        }
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì œí•œ (ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€)
        if len(st.session_state.chat_history) > 10:
            st.session_state.chat_history = st.session_state.chat_history[-10:]
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if user_question := st.chat_input("ì˜ˆ: ì¬ë°©ë¬¸ìœ¨ì„ ë†’ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.chat_history.append({"role": "user", "content": user_question})
            with st.chat_message("user"):
                st.markdown(user_question)
            
            # AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                try:
                    # í”„ë¡¬í”„íŠ¸ ìƒì„± (generate_chatbot_response í•¨ìˆ˜ ë‚´ìš©ì„ ì—¬ê¸°ë¡œ)
                    diagnosis_info = st.session_state.current_diagnosis
                    
                    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (k=1ë¡œ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ)
                    relevant_docs = vectorstore.similarity_search(user_question, k=1)
                    context = "\n\n".join([doc.page_content for doc in relevant_docs])
                    
                    # ì±„íŒ… íˆìŠ¤í† ë¦¬ (ìµœê·¼ 4ê°œë§Œ)
                    recent_history = st.session_state.chat_history[-5:] if len(st.session_state.chat_history) > 5 else st.session_state.chat_history
                    history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in recent_history[:-1]])
                    
                    # ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸
                    prompt = f"""ë‹¹ì‹ ì€ ì„±ë™êµ¬ ì†Œìƒê³µì¸ AI ì»¨ì„¤í„´íŠ¸ 'SAM'ì…ë‹ˆë‹¤.

[ì§„ë‹¨ ì •ë³´]
- íì—… ìœ„í—˜ë„: {diagnosis_info['risk_score']:.1f}ì 
- ì—…ì¢…: {diagnosis_info['ì—…ì¢…']}
- ì§€ì—­: {diagnosis_info['ì§€ì—­']}

[ê´€ë ¨ ì •ì±… ì •ë³´]
{context[:500]}

[ëŒ€í™” íˆìŠ¤í† ë¦¬]
{history_text}

[ì§ˆë¬¸]
{user_question}

âš ï¸ ì¤‘ìš”:
1. 3-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
2. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”

ë‹µë³€:"""
                    
                    # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
                    for chunk in llm.stream(prompt):
                        full_response += chunk.content
                        message_placeholder.markdown(full_response + "â–Œ")
                    
                    message_placeholder.markdown(full_response)
                
                except Exception as e:
                    full_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    message_placeholder.markdown(full_response)
            
            # AI ì‘ë‹µ ì €ì¥
            st.session_state.chat_history.append({"role": "assistant", "content": full_response})

if __name__ == '__main__':
    main()